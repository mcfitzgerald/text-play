{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "normal-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reduced-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint  # pretty-printer\n",
    "from collections import defaultdict\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [\n",
    "    [word for word in document.lower().split() if word not in stoplist]\n",
    "    for document in documents\n",
    "]\n",
    "\n",
    "# remove words that appear only once\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [\n",
    "    [token for token in text if frequency[token] > 1]\n",
    "    for text in texts\n",
    "]\n",
    "\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "induced-longitude",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-13 08:56:18,650 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-02-13 08:56:18,651 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n",
      "2021-02-13 08:56:18,651 : INFO : saving Dictionary object under /tmp/deerwester.dict, separately None\n",
      "2021-02-13 08:56:18,653 : INFO : saved /tmp/deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/tmp/deerwester.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "innocent-frederick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "greenhouse-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "renewable-music",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MmCorpus in module gensim.corpora.mmcorpus:\n",
      "\n",
      "class MmCorpus(gensim.corpora._mmreader.MmReader, gensim.corpora.indexedcorpus.IndexedCorpus)\n",
      " |  MmCorpus(fname)\n",
      " |  \n",
      " |  Corpus serialized using the `sparse coordinate Matrix Market format\n",
      " |  <https://math.nist.gov/MatrixMarket/formats.html>`_.\n",
      " |  \n",
      " |  Wrap a term-document matrix on disk (in matrix-market format), and present it\n",
      " |  as an object which supports iteration over the matrix rows (~documents).\n",
      " |  \n",
      " |  Notable instance attributes:\n",
      " |  \n",
      " |  Attributes\n",
      " |  ------------------\n",
      " |  num_docs : int\n",
      " |      Number of documents in the market matrix file.\n",
      " |  num_terms : int\n",
      " |      Number of features (terms, topics).\n",
      " |  num_nnz : int\n",
      " |      Number of non-zero elements in the sparse MM matrix.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The file is read into memory one document at a time, not the whole matrix at once,\n",
      " |  unlike e.g. `scipy.io.mmread` and other implementations. This allows you to **process corpora which are larger\n",
      " |  than the available RAM**, in a streamed manner.\n",
      " |  \n",
      " |  Example\n",
      " |  --------\n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> from gensim.corpora.mmcorpus import MmCorpus\n",
      " |      >>> from gensim.test.utils import datapath\n",
      " |      >>>\n",
      " |      >>> corpus = MmCorpus(datapath('test_mmcorpus_with_index.mm'))\n",
      " |      >>> for document in corpus:\n",
      " |      ...     pass\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MmCorpus\n",
      " |      gensim.corpora._mmreader.MmReader\n",
      " |      gensim.corpora.indexedcorpus.IndexedCorpus\n",
      " |      gensim.interfaces.CorpusABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fname)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : {str, file-like object}\n",
      " |          Path to file in MM format or a file-like object that supports `seek()`\n",
      " |          (e.g. a compressed file opened by `smart_open <https://github.com/RaRe-Technologies/smart_open>`_).\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Iterate through all documents.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      list of (int, numeric)\n",
      " |          Document in the `sparse Gensim bag-of-words format <intro.rst#core-concepts>`__.\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      The total number of vectors returned is always equal to the number of rows specified in the header.\n",
      " |      Empty documents are inserted and yielded where appropriate, even if they are not explicitly stored in the\n",
      " |      (sparse) Matrix Market file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  save_corpus(fname, corpus, id2word=None, progress_cnt=1000, metadata=False)\n",
      " |      Save a corpus to disk in the sparse coordinate Matrix Market format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file.\n",
      " |      corpus : iterable of list of (int, number)\n",
      " |          Corpus in Bow format.\n",
      " |      id2word : dict of (int, str), optional\n",
      " |          Mapping between word_id -> word. Used to retrieve the total vocabulary size if provided.\n",
      " |          Otherwise, the total vocabulary size is estimated based on the highest feature id encountered in `corpus`.\n",
      " |      progress_cnt : int, optional\n",
      " |          How often to report (log) progress.\n",
      " |      metadata : bool, optional\n",
      " |          Writes out additional metadata?\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      This function is automatically called by :class:`~gensim.corpora.mmcorpus.MmCorpus.serialize`, don't\n",
      " |      call it directly, call :class:`~gensim.corpora.mmcorpus.MmCorpus.serialize` instead.\n",
      " |      \n",
      " |      Example\n",
      " |      -------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora.mmcorpus import MmCorpus\n",
      " |          >>> from gensim.test.utils import datapath\n",
      " |          >>>\n",
      " |          >>> corpus = MmCorpus(datapath('test_mmcorpus_with_index.mm'))\n",
      " |          >>>\n",
      " |          >>> MmCorpus.save_corpus(\"random\", corpus)  # Do not do it, use `serialize` instead.\n",
      " |          [97, 121, 169, 201, 225, 249, 258, 276, 303]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.corpora._mmreader.MmReader:\n",
      " |  \n",
      " |  __len__(...)\n",
      " |      Get the corpus size: total number of documents.\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |      MmReader.__reduce_cython__(self)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |      MmReader.__setstate_cython__(self, __pyx_state)\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  docbyoffset(...)\n",
      " |      MmReader.docbyoffset(self, offset)\n",
      " |      Get the document at file offset `offset` (in bytes).\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              offset : int\n",
      " |                  File offset, in bytes, of the desired document.\n",
      " |      \n",
      " |              Returns\n",
      " |              ------\n",
      " |              list of (int, str)\n",
      " |                  Document in sparse bag-of-words format.\n",
      " |  \n",
      " |  skip_headers(...)\n",
      " |      MmReader.skip_headers(self, input_file)\n",
      " |      Skip file headers that appear before the first document.\n",
      " |      \n",
      " |              Parameters\n",
      " |              ----------\n",
      " |              input_file : iterable of str\n",
      " |                  Iterable taken from file in MM format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from gensim.corpora._mmreader.MmReader:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.corpora._mmreader.MmReader:\n",
      " |  \n",
      " |  input\n",
      " |      input: object\n",
      " |  \n",
      " |  num_docs\n",
      " |      num_docs: 'long long'\n",
      " |  \n",
      " |  num_nnz\n",
      " |      num_nnz: 'long long'\n",
      " |  \n",
      " |  num_terms\n",
      " |      num_terms: 'long long'\n",
      " |  \n",
      " |  transposed\n",
      " |      transposed: 'bool'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.corpora.indexedcorpus.IndexedCorpus:\n",
      " |  \n",
      " |  __getitem__(self, docno)\n",
      " |      Get document by `docno` index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      docno : {int, iterable of int}\n",
      " |          Document number or iterable of numbers (like a list of str).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          If `docno` is int - return document in BoW format.\n",
      " |      \n",
      " |      :class:`~gensim.utils.SlicedCorpus`\n",
      " |          If `docno` is iterable of int - return several documents in BoW format\n",
      " |          wrapped to :class:`~gensim.utils.SlicedCorpus`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      RuntimeError\n",
      " |          If index isn't exist.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gensim.corpora.indexedcorpus.IndexedCorpus:\n",
      " |  \n",
      " |  serialize(fname, corpus, id2word=None, index_fname=None, progress_cnt=None, labels=None, metadata=False) from builtins.type\n",
      " |      Serialize corpus with offset metadata, allows to use direct indexes after loading.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to output file.\n",
      " |      corpus : iterable of iterable of (int, float)\n",
      " |          Corpus in BoW format.\n",
      " |      id2word : dict of (str, str), optional\n",
      " |          Mapping id -> word.\n",
      " |      index_fname : str, optional\n",
      " |           Where to save resulting index, if None - store index to `fname`.index.\n",
      " |      progress_cnt : int, optional\n",
      " |          Number of documents after which progress info is printed.\n",
      " |      labels : bool, optional\n",
      " |           If True - ignore first column (class labels).\n",
      " |      metadata : bool, optional\n",
      " |          If True - ensure that serialize will write out article titles to a pickle file.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.corpora import MmCorpus\n",
      " |          >>> from gensim.test.utils import get_tmpfile\n",
      " |          >>>\n",
      " |          >>> corpus = [[(1, 0.3), (2, 0.1)], [(1, 0.1)], [(2, 0.3)]]\n",
      " |          >>> output_fname = get_tmpfile(\"test.mm\")\n",
      " |          >>>\n",
      " |          >>> MmCorpus.serialize(output_fname, corpus)\n",
      " |          >>> mm = MmCorpus(output_fname)  # `mm` document stream now has random access\n",
      " |          >>> print(mm[1])  # retrieve document no. 42, etc.\n",
      " |          [(1, 0.1)]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.interfaces.CorpusABC:\n",
      " |  \n",
      " |  save(self, *args, **kwargs)\n",
      " |      Saves corpus in-memory state.\n",
      " |      \n",
      " |      Warnings\n",
      " |      --------\n",
      " |      This save only the \"state\" of a corpus class, not the corpus data!\n",
      " |      \n",
      " |      For saving data use the `serialize` method of the output format you'd like to use\n",
      " |      (e.g. :meth:`gensim.corpora.mmcorpus.MmCorpus.serialize`).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  load(fname, mmap=None) from builtins.type\n",
      " |      Load an object previously saved using :meth:`~gensim.utils.SaveLoad.save` from a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to file that contains needed object.\n",
      " |      mmap : str, optional\n",
      " |          Memory-map option.  If the object was saved with large arrays stored separately, you can load these arrays\n",
      " |          via mmap (shared memory) using `mmap='r'.\n",
      " |          If the file being loaded is compressed (either '.gz' or '.bz2'), then `mmap=None` **must be** set.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.utils.SaveLoad.save`\n",
      " |          Save object to file.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object\n",
      " |          Object loaded from `fname`.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          When called on an object instance instead of class (this is a class method).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(corpora.MmCorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-review",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
